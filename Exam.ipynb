{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8df60408-d5d4-4cba-9e53-0c711164341e",
   "metadata": {},
   "source": [
    "Question NO 1\n",
    "Ans:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493023ee-c39b-451b-a110-57701ae21b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 20: 3\n",
      "Updated list: [5, 15, 25, 50]\n"
     ]
    }
   ],
   "source": [
    "listl = [5, 20, 15, 20, 25, 50, 20]\n",
    "\n",
    "# Count occurrences of 20\n",
    "count_20 = listl.count(20)\n",
    "\n",
    "# Remove all occurrences of 20\n",
    "listl = [item for item in listl if item != 20]\n",
    "\n",
    "# Display the results\n",
    "print(\"Count of 20:\", count_20)\n",
    "print(\"Updated list:\", listl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dcd408-615b-4216-9c0a-3d45df31b353",
   "metadata": {},
   "source": [
    "Question No 2\n",
    "Ans:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff835a75-9240-4e22-babe-e37db8065bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial nested dictionary: {'student1': {'name': 'Sudip', 'age': 24, 'grade': 'A'}, 'student2': {'name': 'Sujan', 'age': 22, 'grade': 'B'}}\n",
      "\n",
      "After adding a new key-value pair (student3): {'student1': {'name': 'Sudip', 'age': 24, 'grade': 'A'}, 'student2': {'name': 'Sujan', 'age': 22, 'grade': 'B'}, 'student3': {'name': 'Safalta', 'age': 21, 'grade': 'A'}}\n",
      "\n",
      "After updating student1's age: {'student1': {'name': 'Sudip', 'age': 21, 'grade': 'A'}, 'student2': {'name': 'Sujan', 'age': 22, 'grade': 'B'}, 'student3': {'name': 'Safalta', 'age': 21, 'grade': 'A'}}\n",
      "\n",
      "After deleting student2: {'student1': {'name': 'Sudip', 'age': 21, 'grade': 'A'}, 'student3': {'name': 'Safalta', 'age': 21, 'grade': 'A'}}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a nested dictionary\n",
    "nested_dict = {\n",
    "    'student1': {'name': 'Sudip', 'age': 24, 'grade': 'A'},\n",
    "    'student2': {'name': 'Sujan', 'age': 22, 'grade': 'B'}\n",
    "}\n",
    "\n",
    "# Display the initial nested dictionary\n",
    "print(\"Initial nested dictionary:\", nested_dict)\n",
    "\n",
    "# Addition: Adding a new student entry\n",
    "nested_dict['student3'] = {'name': 'Safalta', 'age': 21, 'grade': 'A'}\n",
    "print(\"\\nAfter adding a new key-value pair (student3):\", nested_dict)\n",
    "\n",
    "# Update: Updating an existing student's age\n",
    "nested_dict['student1']['age'] = 21\n",
    "print(\"\\nAfter updating student1's age:\", nested_dict)\n",
    "\n",
    "# Deletion: Removing a student entry\n",
    "del nested_dict['student2']\n",
    "print(\"\\nAfter deleting student2:\", nested_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc21e2-d74e-4b74-b067-03afa9dbaa8b",
   "metadata": {},
   "source": [
    "Question No. 3 \n",
    "Ans:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6778f26b-2106-432d-b33d-e00dafcd4dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score: 78.57142857142857\n",
      "John obtained a distinction.\n"
     ]
    }
   ],
   "source": [
    "# John's scores\n",
    "john_scores = [80, 75, 90, 65, 70, 80, 90]\n",
    "\n",
    "# Calculate the average score\n",
    "average_score = sum(john_scores) / len(john_scores)\n",
    "\n",
    "# Determine distinction\n",
    "if average_score >= 75:\n",
    "    result = \"John obtained a distinction.\"\n",
    "else:\n",
    "    result = \"John did not obtain a distinction.\"\n",
    "\n",
    "# Display the results\n",
    "print(\"Average Score:\", average_score)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253350bf-2564-4ce4-a5df-1e18734425e5",
   "metadata": {},
   "source": [
    "Question No. 4\n",
    "Ans:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9b59379-ad37-46d7-bb1c-d694f9816bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Student  Math  English  Science  Family Income  Hours of Study at Home  \\\n",
      "0    Ajay  85.0       90     78.0          75000                     3.0   \n",
      "1  Binay_  92.0       88     95.0          80000                     4.0   \n",
      "3     Raj  88.0       92     89.0          90000                     5.0   \n",
      "\n",
      "  Age Group  Distance from School (km)  Number of Siblings  \\\n",
      "0     11-20                        2.5                   2   \n",
      "1     21-30                        3.0                   1   \n",
      "3     21-30                        4.2                   0   \n",
      "\n",
      "   Extracurricular Activities Motivation Level  \n",
      "0                           1             High  \n",
      "1                           1           Medium  \n",
      "3                           1             High  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"./student_scores.csv\") \n",
    "# Filter rows where 'Math' score is above 80 and 'Science' score is not missing\n",
    "filtered_df = df[(df['Math'] > 80) & (df['Science'].notna())]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9885b5c-b76d-4a30-9dff-f005c5cc4631",
   "metadata": {},
   "source": [
    "Question No. 5\n",
    "Ans:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b7e6a75-86ba-4fc3-8c8f-5886c5d4c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median values for each subject:\n",
      "Math: 80.0\n",
      "English: 88.0\n",
      "Science: 85.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./student_scores.csv')\n",
    "\n",
    "# Calculate the median values for each subject (Math, English, Science)\n",
    "median_values = df[['Math', 'English', 'Science']].median()\n",
    "\n",
    "# Display the median values\n",
    "print(\"Median values for each subject:\")\n",
    "print(\"Math:\", median_values['Math'])\n",
    "print(\"English:\", median_values['English'])\n",
    "print(\"Science:\", median_values['Science'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791923c1-1b92-4d56-b5da-d58779a6d4f1",
   "metadata": {},
   "source": [
    "Question No. 6\n",
    "Ans:-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c855c8f3-91af-4794-b228-8f364d20d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after replacing missing values with median values:\n",
      "   Student  Math  English  Science  Family Income  Hours of Study at Home  \\\n",
      "0     Ajay  85.0       90     78.0          75000                     3.0   \n",
      "1   Binay_  92.0       88     95.0          80000                     4.0   \n",
      "2   Amrita  75.0       80     82.0          60000                     2.0   \n",
      "3      Raj  88.0       92     89.0          90000                     5.0   \n",
      "4  Sa nj u  60.0       77     85.0          55000                     1.0   \n",
      "5    Pujan   2.0       85     85.0          40000                     3.5   \n",
      "6  Prabesh  80.0      900     85.0         100000                     6.0   \n",
      "\n",
      "  Age Group  Distance from School (km)  Number of Siblings  \\\n",
      "0     11-20                        2.5                   2   \n",
      "1     21-30                        3.0                   1   \n",
      "2     11-20                        1.8                   3   \n",
      "3     21-30                        4.2                   0   \n",
      "4     11-20                        2.0                   4   \n",
      "5      0-10                        0.5                   0   \n",
      "6     21-30                        5.5                   2   \n",
      "\n",
      "   Extracurricular Activities Motivation Level  \n",
      "0                           1             High  \n",
      "1                           1           Medium  \n",
      "2                           0           Medium  \n",
      "3                           1             High  \n",
      "4                           0              Low  \n",
      "5                           0              Low  \n",
      "6                           1             High  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2872\\2459496827.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)  # Replace NaN values with median\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2872\\2459496827.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)  # Replace NaN values with median\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2872\\2459496827.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)  # Replace NaN values with median\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2872\\2459496827.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)  # Replace NaN values with median\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2872\\2459496827.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)  # Replace NaN values with median\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2872\\2459496827.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)  # Replace NaN values with median\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2872\\2459496827.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)  # Replace NaN values with median\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_2872\\2459496827.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(median_value, inplace=True)  # Replace NaN values with median\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./student_scores.csv')\n",
    "\n",
    "# Loop through each column in the DataFrame\n",
    "for column in df.columns:\n",
    "    # Check if the column contains numeric data (only calculate median for numeric columns)\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        median_value = df[column].median()  # Calculate the median for the column\n",
    "        df[column].fillna(median_value, inplace=True)  # Replace NaN values with median\n",
    "\n",
    "# Display the DataFrame after replacing missing values with median values\n",
    "print(\"Data after replacing missing values with median values:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23417638-3c60-4945-87ed-228cdefea551",
   "metadata": {},
   "source": [
    "Question No 7\n",
    "Ans:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14c6c793-1bea-4be7-91e2-a80d54067782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after replacing outliers with mean values:\n",
      "   Student  Math     English  Science  Family Income  Hours of Study at Home  \\\n",
      "0     Ajay  85.0   90.000000     78.0          75000                     3.0   \n",
      "1   Binay_  92.0   88.000000     95.0          80000                     4.0   \n",
      "2   Amrita  75.0   80.000000     82.0          60000                     2.0   \n",
      "3      Raj  88.0   92.000000     89.0          90000                     5.0   \n",
      "4  Sa nj u  60.0   77.000000      NaN          55000                     1.0   \n",
      "5    Pujan  67.0   85.000000      NaN          40000                     NaN   \n",
      "6  Prabesh   NaN  201.714286     85.0         100000                     6.0   \n",
      "\n",
      "  Age Group  Distance from School (km)  Number of Siblings  \\\n",
      "0     11-20                        2.5                   2   \n",
      "1     21-30                        3.0                   1   \n",
      "2     11-20                        1.8                   3   \n",
      "3     21-30                        4.2                   0   \n",
      "4     11-20                        2.0                   4   \n",
      "5      0-10                        0.5                   0   \n",
      "6     21-30                        5.5                   2   \n",
      "\n",
      "   Extracurricular Activities Motivation Level  \n",
      "0                           1             High  \n",
      "1                           1           Medium  \n",
      "2                           0           Medium  \n",
      "3                           1             High  \n",
      "4                           0              Low  \n",
      "5                           0              Low  \n",
      "6                           1             High  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('./student_scores.csv')\n",
    "\n",
    "# Loop through each column in the DataFrame\n",
    "for column in df.columns:\n",
    "    # Check if the column is numeric to detect and replace outliers\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        # Calculate Q1, Q3, and IQR\n",
    "        Q1 = df[column].quantile(0.25)\n",
    "        Q3 = df[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        # Calculate the mean of the column\n",
    "        mean_value = df[column].mean()\n",
    "\n",
    "        # Replace outliers with the mean\n",
    "        df[column] = df[column].apply(lambda x: mean_value if x < lower_bound or x > upper_bound else x)\n",
    "\n",
    "# Display the DataFrame after replacing outliers with mean values\n",
    "print(\"Data after replacing outliers with mean values:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281256ec-907d-4c05-a187-4c8528ef5fe5",
   "metadata": {},
   "source": [
    "Question No 8\n",
    "ans :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f491b5f9-8bda-42de-b778-f2d70e2c8841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Student  Math  English  Science  Family Income  Hours of Study at Home  \\\n",
      "0     Ajay  85.0       90     78.0          75000                     3.0   \n",
      "1   Binay_  92.0       88     95.0          80000                     4.0   \n",
      "2   Amrita  75.0       80     82.0          60000                     2.0   \n",
      "3      Raj  88.0       92     89.0          90000                     5.0   \n",
      "4  Sa nj u  60.0       77      NaN          55000                     1.0   \n",
      "5    Pujan   2.0       85      NaN          40000                     NaN   \n",
      "6  Prabesh   NaN      900     85.0         100000                     6.0   \n",
      "\n",
      "  Age Group  Distance from School (km)  Number of Siblings  \\\n",
      "0     11-20                        2.5                   2   \n",
      "1     21-30                        3.0                   1   \n",
      "2     11-20                        1.8                   3   \n",
      "3     21-30                        4.2                   0   \n",
      "4     11-20                        2.0                   4   \n",
      "5      0-10                        0.5                   0   \n",
      "6     21-30                        5.5                   2   \n",
      "\n",
      "   Extracurricular Activities Motivation Level  \n",
      "0                           1             High  \n",
      "1                           1           Medium  \n",
      "2                           0           Medium  \n",
      "3                           1             High  \n",
      "4                           0              Low  \n",
      "5                           0              Low  \n",
      "6                           1             High  \n",
      "\n",
      "Cleaned DataFrame with Total Score:\n",
      "   Student  Math  English  Science  Family Income  Hours of Study at Home  \\\n",
      "0     Ajay  85.0       90     78.0          75000                     3.0   \n",
      "1   Binay_  92.0       88     95.0          80000                     4.0   \n",
      "2   Amrita  75.0       80     82.0          60000                     2.0   \n",
      "3      Raj  88.0       92     89.0          90000                     5.0   \n",
      "4  Sa nj u  60.0       77      0.0          55000                     1.0   \n",
      "5    Pujan   2.0       85      0.0          40000                     0.0   \n",
      "6  Prabesh   0.0      900     85.0         100000                     6.0   \n",
      "\n",
      "  Age Group  Distance from School (km)  Number of Siblings  \\\n",
      "0     11-20                        2.5                   2   \n",
      "1     21-30                        3.0                   1   \n",
      "2     11-20                        1.8                   3   \n",
      "3     21-30                        4.2                   0   \n",
      "4     11-20                        2.0                   4   \n",
      "5      0-10                        0.5                   0   \n",
      "6     21-30                        5.5                   2   \n",
      "\n",
      "   Extracurricular Activities Motivation Level  Total Score  \n",
      "0                           1             High        253.0  \n",
      "1                           1           Medium        275.0  \n",
      "2                           0           Medium        237.0  \n",
      "3                           1             High        269.0  \n",
      "4                           0              Low        137.0  \n",
      "5                           0              Low         87.0  \n",
      "6                           1             High        985.0  \n",
      "\n",
      "Cleaned data saved to cleaned_student_scores.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the CSV file into a DataFrame\n",
    "file_path = './student_scores.csv'  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Step 2: Clean the string columns\n",
    "# Assuming the subject columns are named 'Math', 'Science', 'English', etc.\n",
    "subject_columns = ['Math', 'Science', 'English']  # Adjust according to your actual column names\n",
    "\n",
    "# Convert to numeric, forcing errors to NaN\n",
    "for column in subject_columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "# Optionally fill NaN values with 0 (or you can drop them)\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the total score\n",
    "df['Total Score'] = df[subject_columns].sum(axis=1)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nCleaned DataFrame with Total Score:\")\n",
    "print(df)\n",
    "\n",
    "# Step 4: Save the cleaned DataFrame to a new CSV file (optional)\n",
    "cleaned_file_path = 'cleaned_student_scores.csv'  # Replace with your desired output file path\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f\"\\nCleaned data saved to {cleaned_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "588ff9cc-c005-4071-969f-1d9e7b3e6263",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Total Score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Total Score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Visualization 1: Distribution of Total Scores\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m---> 11\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, kde\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Total Scores\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Total Score'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "file_path = './student_scores.csv'  # Replace with your actual file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Visualization 1: Distribution of Total Scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Total Score'], bins=10, kde=True)\n",
    "plt.title('Distribution of Total Scores')\n",
    "plt.xlabel('Total Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Boxplot of Scores by Subject\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df[subject_columns])\n",
    "plt.title('Boxplot of Scores by Subject')\n",
    "plt.ylabel('Scores')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Correlation Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "correlation_matrix = df[subject_columns + ['Total Score']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58e52048-5a02-4b37-afd6-6cd94e5a88f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Data:\n",
      "       Math   Science   English\n",
      "0  0.922222  0.000000  0.015796\n",
      "1  1.000000  1.000000  0.013366\n",
      "2  0.811111  0.235294  0.003645\n",
      "3  0.955556  0.647059  0.018226\n",
      "4  0.644444       NaN  0.000000\n",
      "\n",
      "Standardized Data:\n",
      "       Math   Science   English\n",
      "0  0.582568 -1.334553 -0.391819\n",
      "1  0.809122  1.574088 -0.398834\n",
      "2  0.258919 -0.650167 -0.426893\n",
      "3  0.679663  0.547509 -0.384805\n",
      "4 -0.226554       NaN -0.437415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Normalize the features (Min-Max Scaling)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "normalized_data = min_max_scaler.fit_transform(df[subject_columns])\n",
    "normalized_df = pd.DataFrame(normalized_data, columns=subject_columns)\n",
    "\n",
    "# Standardize the features (Z-score Scaling)\n",
    "standard_scaler = StandardScaler()\n",
    "standardized_data = standard_scaler.fit_transform(df[subject_columns])\n",
    "standardized_df = pd.DataFrame(standardized_data, columns=subject_columns)\n",
    "\n",
    "# Display the normalized and standardized DataFrames\n",
    "print(\"Normalized Data:\")\n",
    "print(normalized_df.head())\n",
    "\n",
    "print(\"\\nStandardized Data:\")\n",
    "print(standardized_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dd67d09-4a77-4ab8-babe-cb4a131577c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Total Score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Total Score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Define features and target variable\u001b[39;00m\n\u001b[0;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m df[subject_columns]  \u001b[38;5;66;03m# Features\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m    \u001b[38;5;66;03m# Target variable\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets\u001b[39;00m\n\u001b[0;32m     10\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Total Score'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define features and target variable\n",
    "X = df[subject_columns]  # Features\n",
    "y = df['Total Score']    # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the total score\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"y_test: {y_test.values}\")\n",
    "print(f\"y_predicted: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c9b04fc-af86-4f6b-963b-4cd9f9b9a415",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the results dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults_file_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace with your actual file path\u001b[39;00m\n\u001b[0;32m      6\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(results_file_path)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Define features and target variable\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Load the results dataset\n",
    "pd.read_csv(results_file_path)  # Replace with your actual file path\n",
    "results_df = pd.read_csv(results_file_path)\n",
    "\n",
    "# Define features and target variable\n",
    "X_results = results_df.drop('Pass/Fail', axis=1)  # Features (adjust column name)\n",
    "y_results = results_df['Pass/Fail']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_results, X_test_results, y_train_results, y_test_results = train_test_split(X_results, y_results, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train_results, y_train_results)\n",
    "\n",
    "# Predict pass/fail\n",
    "y_pred_results = logistic_model.predict(X_test_results)\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "accuracy = accuracy_score(y_test_results, y_pred_results)\n",
    "confusion = confusion_matrix(y_test_results, y_pred_results)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion}\")\n",
    "print(f\"y_test: {y_test_results.values}\")\n",
    "print(f\"y_predicted: {y_pred_results}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
